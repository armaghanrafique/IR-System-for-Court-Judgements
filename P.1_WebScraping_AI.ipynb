{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46675b3b-f692-4c70-a685-2760e0d6664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üèõÔ∏è  SUPREME COURT PAKISTAN - SMART PDF DOWNLOADER\n",
      "======================================================================\n",
      "\n",
      "üöÄ Starting browser (visible mode to debug)...\n",
      "\n",
      "üåê Loading: https://sacgb.gov.pk/Judgments.html\n",
      "üîç Analyzing page structure...\n",
      "‚úÖ Found 1396 direct PDF links\n",
      "‚úÖ Found 10 other potential judgement links\n",
      "\n",
      "üìã Direct PDF links found:\n",
      "  1. CPLA No.75/2019\n",
      "Prov. Govt. of GB Vs. Saadat Khan... ‚Üí https://sacgb.gov.pk/Judgments/judgements-2021/1.%20judgment%20of%20Saadat%20Kha...\n",
      "  2. CPLA No. 98/2020\n",
      "Provincial Govt. through Chief Se... ‚Üí https://sacgb.gov.pk/Judgments/judgements-2021/2.%20final%20Judgment%20of%20Akht...\n",
      "  3. CPLA No.138/2020\n",
      "Prov. Government GB through Chief... ‚Üí https://sacgb.gov.pk/Judgments/judgements-2021/3.%20judgement%20of%20Naveed%20En...\n",
      "  4. CPLA No.51/2018\n",
      "Govt. of GB through Chief Secretar... ‚Üí https://sacgb.gov.pk/Judgments/judgements-2021/4.%20final%20judgment%20of%20shah...\n",
      "  5. CPLA U/O No.152/2019\n",
      "Govt. of GB through Chief Sec... ‚Üí https://sacgb.gov.pk/Judgments/judgements-2021/5.%20final%20judgment%20of%20nafe...\n",
      "\n",
      "üîç Looking for judgement items...\n",
      "‚úÖ Found 740 elements with selector: 'tr'\n",
      "  Sample 1: Case Title...\n",
      "  Sample 2: CPLA No.75/2019\n",
      "Prov. Govt. of GB Vs. Saadat Khan...\n",
      "    Contains 1 PDF link(s)\n",
      "  Sample 3: CPLA No. 98/2020\n",
      "Provincial Govt. through Chief Secretary GB, Gilgit Versus Akhtar Hussain S/o Ghula...\n",
      "    Contains 1 PDF link(s)\n",
      "\n",
      "üì• Ready to download 1396 PDF(s)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[1/1396] CPLA No.75/2019\n",
      "Prov. Govt. of GB Vs. Saadat Khan...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No752019_Prov_Govt_of_GB_Vs_Saadat_Khan_1._20judgment_20of_20Saadat_20Khan.pdf\n",
      "  ‚úÖ Success (561 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[2/1396] CPLA No. 98/2020\n",
      "Provincial Govt. through Chief Secretary GB...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No_982020_Provincial_Govt_through_Chief_Se_2._20final_20Judgment_20of_20Akhtar_20Hussain_20_1_.pdf\n",
      "  ‚úÖ Success (421 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[3/1396] CPLA No.138/2020\n",
      "Prov. Government GB through Chief Secretary...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No1382020_Prov_Government_GB_through_Chief_3._20judgement_20of_20Naveed_20Enterprises.pdf\n",
      "  ‚úÖ Success (428 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[4/1396] CPLA No.51/2018\n",
      "Govt. of GB through Chief Secretary GB Versu...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No512018_Govt_of_GB_through_Chief_Secretar_4._20final_20judgment_20of_20shah_20faisal__20luqman_20wali.pdf\n",
      "  ‚úÖ Success (479 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[5/1396] CPLA U/O No.152/2019\n",
      "Govt. of GB through Chief Secretary GB ...\n",
      "‚¨áÔ∏è  Direct download: CPLA_UO_No1522019_Govt_of_GB_through_Chief_Sec_5._20final_20judgment_20of_20nafeesa_20kiran.pdf\n",
      "  ‚úÖ Success (440 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[6/1396] CPLA No. 89/2020\n",
      "Govt. of Gilgit-Baltistan through Chief Sec...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No_892020_Govt_of_Gilgit-Baltistan_through_6._20judgment_20of_20safiullah.pdf\n",
      "  ‚úÖ Success (553 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[7/1396] CPLA No. 105/2019\n",
      "Chief Secretary Govt. of Gilgit-Baltistan ...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No_1052019_Chief_Secretary_Govt_of_Gilgit-_7._20judgment_20of_20Ali_20Jan.pdf\n",
      "  ‚úÖ Success (485 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[8/1396] CPLA No.50/2019\n",
      "Govt. of Gilgit-Baltistan through Chief Secr...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No502019_Govt_of_Gilgit-Baltistan_through_8._20judgment_20of_20dr._20fida.pdf\n",
      "  ‚úÖ Success (443 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[9/1396] CPLA Under Objection No.17/2020\n",
      "Darwesh and another Versus S...\n",
      "‚¨áÔ∏è  Direct download: CPLA_Under_Objection_No172020_Darwesh_and_anothe_9._20judgment_20of_20Darwesh-2.pdf\n",
      "  ‚úÖ Success (544 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[10/1396] CPLA No.97/2018\n",
      "Govt. of Gilgit-Baltistan through Chief Secr...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No972018_Govt_of_Gilgit-Baltistan_through_10._20judgment_20of_20Dr._20Qazi_20Muhammad_20Saleem.pdf\n",
      "  ‚úÖ Success (440 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[11/1396] CPLA Under Objection No. 85/2019\n",
      "Govt. of Gilgit-Baltistan t...\n",
      "‚¨áÔ∏è  Direct download: CPLA_Under_Objection_No_852019_Govt_of_Gilgit-B_11._20judgement_20of_20Akhtar_20Hussain_20Changazi.pdf\n",
      "  ‚úÖ Success (489 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[12/1396] CPLA No. 34/2020\n",
      "Provincial Government through Chief Secreta...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No_342020_Provincial_Government_through_Chi_12._20judgement_20of_20Amir_20Munir.pdf\n",
      "  ‚úÖ Success (750 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[13/1396] CPLA NO. 33/2018\n",
      "Provincial Government through Chief Secreta...\n",
      "‚¨áÔ∏è  Direct download: CPLA_NO_332018_Provincial_Government_through_Chi_13._20judgment_20of_20Raziq_20Hussain.pdf\n",
      "  ‚úÖ Success (465 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[14/1396] CPLA Under Objection No.142/2019\n",
      "Inspector General of Police...\n",
      "‚¨áÔ∏è  Direct download: CPLA_Under_Objection_No1422019_Inspector_General_14._20judgment_20of_20Waqar_20Hussain.pdf\n",
      "  ‚úÖ Success (429 KB)\n",
      "   ‚è≥ Waiting 3 seconds...\n",
      "\n",
      "[15/1396] CPLA No.60/2018\n",
      "Provincial Government through Chief Secretar...\n",
      "‚¨áÔ∏è  Direct download: CPLA_No602018_Provincial_Government_through_Chie_15._20judgment_20of_20Raja_20Muhammad_20Haleem_20Khan.pdf\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import re\n",
    "\n",
    "def setup_driver(headless=True):\n",
    "    \"\"\"Setup Chrome driver with proper options\"\"\"\n",
    "    chrome_options = Options()\n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    # Important: Allow downloads\n",
    "    prefs = {\n",
    "        \"download.default_directory\": os.path.join(os.getcwd(), \"supreme_court_judgements\"),\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"plugins.always_open_pdf_externally\": True,\n",
    "        \"profile.default_content_setting_values.automatic_downloads\": 1\n",
    "    }\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    \n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def analyze_page_structure(driver, url):\n",
    "    \"\"\"Analyze the actual page structure to find PDFs\"\"\"\n",
    "    print(\"üîç Analyzing page structure...\")\n",
    "    \n",
    "    # Get all links on the page\n",
    "    all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    \n",
    "    pdf_links = []\n",
    "    other_links = []\n",
    "    \n",
    "    for link in all_links:\n",
    "        try:\n",
    "            href = link.get_attribute('href')\n",
    "            text = link.text.strip()\n",
    "            \n",
    "            if href:\n",
    "                if '.pdf' in href.lower():\n",
    "                    pdf_links.append({\n",
    "                        'url': href,\n",
    "                        'text': text or 'No text',\n",
    "                        'element': link\n",
    "                    })\n",
    "                else:\n",
    "                    # Check if it might be a judgement link\n",
    "                    if any(word in (text + href).lower() for word in ['judgement', 'judgment', 'case', 'download', 'view']):\n",
    "                        other_links.append({\n",
    "                            'url': href,\n",
    "                            'text': text or 'No text'\n",
    "                        })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(pdf_links)} direct PDF links\")\n",
    "    print(f\"‚úÖ Found {len(other_links)} other potential judgement links\")\n",
    "    \n",
    "    # Show first few PDF links\n",
    "    if pdf_links:\n",
    "        print(\"\\nüìã Direct PDF links found:\")\n",
    "        for i, pdf in enumerate(pdf_links[:5], 1):\n",
    "            print(f\"  {i}. {pdf['text'][:50]}... ‚Üí {pdf['url'][:80]}...\")\n",
    "    \n",
    "    return pdf_links, other_links\n",
    "\n",
    "def extract_judgement_details(driver):\n",
    "    \"\"\"Extract judgement details from the page\"\"\"\n",
    "    print(\"\\nüîç Looking for judgement items...\")\n",
    "    \n",
    "    # Common selectors for judgement containers\n",
    "    selectors_to_try = [\n",
    "        \"div.judgement\", \"div.judgment\", \"div.item\", \"article\", \n",
    "        \"div.card\", \"li.judgement\", \"div.list-item\", \"tr\",\n",
    "        \"div.post\", \"div.entry\", \"div.content-item\"\n",
    "    ]\n",
    "    \n",
    "    judgements = []\n",
    "    \n",
    "    for selector in selectors_to_try:\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if elements and len(elements) > 2:  # More than 2 suggests it's the right selector\n",
    "                print(f\"‚úÖ Found {len(elements)} elements with selector: '{selector}'\")\n",
    "                \n",
    "                # Try to extract info from first few\n",
    "                for i, elem in enumerate(elements[:3]):\n",
    "                    try:\n",
    "                        text = elem.text[:200] if elem.text else \"No text\"\n",
    "                        print(f\"  Sample {i+1}: {text[:100]}...\")\n",
    "                        \n",
    "                        # Look for PDF links within this element\n",
    "                        pdf_links_in_elem = elem.find_elements(By.CSS_SELECTOR, \"a[href*='.pdf']\")\n",
    "                        if pdf_links_in_elem:\n",
    "                            print(f\"    Contains {len(pdf_links_in_elem)} PDF link(s)\")\n",
    "                            \n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                judgements = elements\n",
    "                break\n",
    "                \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return judgements\n",
    "\n",
    "def get_pdf_links_from_analysis(driver, url):\n",
    "    \"\"\"Main function to get PDF links using multiple methods\"\"\"\n",
    "    \n",
    "    # Method 1: Direct PDF links on page\n",
    "    direct_pdfs, other_links = analyze_page_structure(driver, url)\n",
    "    \n",
    "    # Method 2: Extract from judgement containers\n",
    "    judgements = extract_judgement_details(driver)\n",
    "    \n",
    "    pdf_list = []\n",
    "    \n",
    "    # Add direct PDFs\n",
    "    for pdf in direct_pdfs:\n",
    "        pdf_list.append({\n",
    "            'url': pdf['url'],\n",
    "            'filename': create_filename_from_url(pdf['url'], pdf['text']),\n",
    "            'title': pdf['text'][:100]\n",
    "        })\n",
    "    \n",
    "    # If we found judgement containers but no PDFs, they might be on detail pages\n",
    "    if judgements and not pdf_list:\n",
    "        print(\"\\n‚ö†Ô∏è Found judgement containers but no direct PDFs.\")\n",
    "        print(\"PDFs might be on individual case pages.\")\n",
    "        print(f\"Found {len(other_links)} potential case detail links\")\n",
    "        \n",
    "        # Check first few detail links for PDFs\n",
    "        for i, link_info in enumerate(other_links[:3]):\n",
    "            print(f\"\\nChecking detail page {i+1}: {link_info['text'][:50]}...\")\n",
    "            \n",
    "            try:\n",
    "                # Open the detail page\n",
    "                driver.execute_script(\"window.open('');\")\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                driver.get(link_info['url'])\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Look for PDFs on detail page\n",
    "                detail_pdfs = driver.find_elements(By.CSS_SELECTOR, \"a[href*='.pdf']\")\n",
    "                if detail_pdfs:\n",
    "                    print(f\"  ‚úÖ Found {len(detail_pdfs)} PDF(s) on detail page\")\n",
    "                    for pdf_elem in detail_pdfs[:2]:  # Take first 2\n",
    "                        pdf_url = pdf_elem.get_attribute('href')\n",
    "                        pdf_text = pdf_elem.text.strip() or link_info['text']\n",
    "                        \n",
    "                        pdf_list.append({\n",
    "                            'url': pdf_url,\n",
    "                            'filename': create_filename_from_url(pdf_url, pdf_text),\n",
    "                            'title': pdf_text[:100]\n",
    "                        })\n",
    "                \n",
    "                # Close detail tab\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error checking detail page: {e}\")\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "    \n",
    "    return pdf_list\n",
    "\n",
    "def create_filename_from_url(url, title):\n",
    "    \"\"\"Create a clean filename from URL and title\"\"\"\n",
    "    # Get base filename from URL\n",
    "    if '/' in url:\n",
    "        basename = url.split('/')[-1]\n",
    "        if '?' in basename:\n",
    "            basename = basename.split('?')[0]\n",
    "    else:\n",
    "        basename = url\n",
    "    \n",
    "    # If it doesn't end with .pdf, add it\n",
    "    if not basename.lower().endswith('.pdf'):\n",
    "        basename += '.pdf'\n",
    "    \n",
    "    # Clean the filename\n",
    "    basename = re.sub(r'[^\\w\\.\\-]', '_', basename)\n",
    "    \n",
    "    # If title is meaningful, use it\n",
    "    clean_title = re.sub(r'[^\\w\\s\\-]', '', title[:50])\n",
    "    clean_title = re.sub(r'\\s+', '_', clean_title.strip())\n",
    "    \n",
    "    if clean_title and len(clean_title) > 5:\n",
    "        filename = f\"{clean_title}_{basename}\"\n",
    "    else:\n",
    "        filename = basename\n",
    "    \n",
    "    return filename[:150]  # Limit length\n",
    "\n",
    "def download_pdf_selenium(driver, pdf_url, download_folder):\n",
    "    \"\"\"Download PDF using Selenium (for sites that require browser session)\"\"\"\n",
    "    try:\n",
    "        print(f\"‚¨áÔ∏è  Attempting Selenium download: {pdf_url[:80]}...\")\n",
    "        \n",
    "        # Open PDF in new tab\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        \n",
    "        # Navigate to PDF\n",
    "        driver.get(pdf_url)\n",
    "        time.sleep(3)  # Wait for PDF to load/start download\n",
    "        \n",
    "        # In headless mode, PDFs usually auto-download to default directory\n",
    "        print(\"  ‚è≥ PDF should be downloading...\")\n",
    "        \n",
    "        # Close the PDF tab\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "        # Check if file was downloaded\n",
    "        time.sleep(2)\n",
    "        download_dir = download_folder\n",
    "        files_before = set(os.listdir(download_dir)) if os.path.exists(download_dir) else set()\n",
    "        \n",
    "        # Wait a bit for download to complete\n",
    "        time.sleep(3)\n",
    "        \n",
    "        files_after = set(os.listdir(download_dir)) if os.path.exists(download_dir) else set()\n",
    "        new_files = files_after - files_before\n",
    "        \n",
    "        if new_files:\n",
    "            for file in new_files:\n",
    "                if file.lower().endswith('.pdf') or '.pdf' in file.lower():\n",
    "                    filepath = os.path.join(download_dir, file)\n",
    "                    size = os.path.getsize(filepath) // 1024 if os.path.exists(filepath) else 0\n",
    "                    print(f\"  ‚úÖ Downloaded: {file} ({size} KB)\")\n",
    "                    return True\n",
    "        \n",
    "        print(\"  ‚ö†Ô∏è PDF may not have downloaded automatically\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Selenium download failed: {str(e)[:100]}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Ensure we're back to main window\n",
    "        if len(driver.window_handles) > 1:\n",
    "            try:\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                driver.close()\n",
    "            except:\n",
    "                pass\n",
    "        if driver.window_handles:\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "def download_pdf_direct(pdf_info, download_folder):\n",
    "    \"\"\"Try direct download with requests\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'application/pdf, */*',\n",
    "            'Referer': 'https://www.supremecourt.gov.pk/'\n",
    "        }\n",
    "        \n",
    "        print(f\"‚¨áÔ∏è  Direct download: {pdf_info['filename']}\")\n",
    "        \n",
    "        response = requests.get(pdf_info['url'], headers=headers, stream=True, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Check if it's a PDF\n",
    "        if 'pdf' not in response.headers.get('content-type', '').lower():\n",
    "            # Check content\n",
    "            if response.content[:4] != b'%PDF':\n",
    "                print(f\"  ‚ö†Ô∏è Not a PDF file\")\n",
    "                return False\n",
    "        \n",
    "        # Ensure download folder exists\n",
    "        if not os.path.exists(download_folder):\n",
    "            os.makedirs(download_folder)\n",
    "        \n",
    "        # Create filepath\n",
    "        filepath = os.path.join(download_folder, pdf_info['filename'])\n",
    "        \n",
    "        # Make filename unique\n",
    "        counter = 1\n",
    "        original_path = filepath\n",
    "        while os.path.exists(filepath):\n",
    "            name, ext = os.path.splitext(pdf_info['filename'])\n",
    "            filepath = os.path.join(download_folder, f\"{name}_{counter}{ext}\")\n",
    "            counter += 1\n",
    "        \n",
    "        # Save file\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        \n",
    "        size = os.path.getsize(filepath) // 1024\n",
    "        print(f\"  ‚úÖ Success ({size} KB)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Direct download failed: {str(e)[:100]}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    TARGET_URL = \"https://sacgb.gov.pk/Judgments.html\"\n",
    "    DOWNLOAD_FOLDER = \"supreme_court_judgements\"\n",
    "    DELAY = 3\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üèõÔ∏è  SUPREME COURT PAKISTAN - SMART PDF DOWNLOADER\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create download folder\n",
    "    if not os.path.exists(DOWNLOAD_FOLDER):\n",
    "        os.makedirs(DOWNLOAD_FOLDER)\n",
    "    \n",
    "    # Start with NON-headless to see what's happening\n",
    "    print(\"\\nüöÄ Starting browser (visible mode to debug)...\")\n",
    "    driver = setup_driver(headless=False)  # Changed to False for debugging\n",
    "    \n",
    "    try:\n",
    "        # Load the page\n",
    "        print(f\"\\nüåê Loading: {TARGET_URL}\")\n",
    "        driver.get(TARGET_URL)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Analyze page and get PDF links\n",
    "        pdf_list = get_pdf_links_from_analysis(driver, TARGET_URL)\n",
    "        \n",
    "        if not pdf_list:\n",
    "            print(\"\\n‚ùå No PDFs found. Possible reasons:\")\n",
    "            print(\"   1. PDFs are behind login or not publicly accessible\")\n",
    "            print(\"   2. PDFs are loaded via different mechanism\")\n",
    "            print(\"   3. The page structure has changed\")\n",
    "            print(\"\\nüí° Check the browser window that opened to see the actual page.\")\n",
    "            input(\"Press Enter after inspecting the page...\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüì• Ready to download {len(pdf_list)} PDF(s)\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Try downloading\n",
    "        downloaded = 0\n",
    "        for i, pdf_info in enumerate(pdf_list, 1):\n",
    "            print(f\"\\n[{i}/{len(pdf_list)}] {pdf_info['title'][:60]}...\")\n",
    "            \n",
    "            # First try direct download\n",
    "            if not download_pdf_direct(pdf_info, DOWNLOAD_FOLDER):\n",
    "                # If direct fails, try selenium download\n",
    "                print(\"  ‚ö†Ô∏è Direct download failed, trying Selenium method...\")\n",
    "                if download_pdf_selenium(driver, pdf_info['url'], DOWNLOAD_FOLDER):\n",
    "                    downloaded += 1\n",
    "            else:\n",
    "                downloaded += 1\n",
    "            \n",
    "            # Delay between downloads\n",
    "            if i < len(pdf_list):\n",
    "                print(f\"   ‚è≥ Waiting {DELAY} seconds...\")\n",
    "                time.sleep(DELAY)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìä FINAL SUMMARY\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"‚úÖ Successfully downloaded: {downloaded}/{len(pdf_list)}\")\n",
    "        print(f\"üìÅ Location: {os.path.abspath(DOWNLOAD_FOLDER)}\")\n",
    "        \n",
    "        # List downloaded files\n",
    "        if os.path.exists(DOWNLOAD_FOLDER):\n",
    "            pdf_files = [f for f in os.listdir(DOWNLOAD_FOLDER) if f.lower().endswith('.pdf')]\n",
    "            if pdf_files:\n",
    "                print(f\"\\nüìã Downloaded {len(pdf_files)} PDF file(s):\")\n",
    "                for file in pdf_files[:10]:\n",
    "                    size = os.path.getsize(os.path.join(DOWNLOAD_FOLDER, file)) // 1024\n",
    "                    print(f\"   ‚Ä¢ {file[:60]}... ({size} KB)\")\n",
    "        \n",
    "        print(\"\\nüí° Tips if downloads failed:\")\n",
    "        print(\"   1. Check if PDFs require clicking 'Download' button\")\n",
    "        print(\"   2. PDFs might be behind additional pages\")\n",
    "        print(\"   3. Try manual download to understand the flow\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        input(\"\\nPress Enter to close browser...\")\n",
    "        driver.quit()\n",
    "        print(\"üéâ Process completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check/install dependencies\n",
    "    try:\n",
    "        from bs4 import BeautifulSoup\n",
    "    except ImportError:\n",
    "        print(\"Installing required packages...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([\"pip\", \"install\", \"beautifulsoup4\", \"selenium\", \"webdriver-manager\", \"requests\"])\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6fb21-384a-4df0-a2c3-57f6279ad980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
